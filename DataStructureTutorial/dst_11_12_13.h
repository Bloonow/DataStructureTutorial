// Author：Akame Qixisi / Excel Bloonow
// 作者： 巫见 / 血梦墨雪

#ifndef DST_11_12_13
#define DST_11_12_13

// 第十一章：外排序
// 第十二章：文件
// 第十三章：采用面向对象的方法描述算法
// 由于教材中以上三章内容无实现代码，只是论述思想，故将这三章归于此头文件

// 数据结构教程（第5版） 清华大学出版社
// Data Structure Tutorial
namespace dst {
	// 11 外排序（external sort）
	namespace _11 {
		// 11.1 外排序概述
		// 文件存储在外存上，因此外排序方法与各种外存设备的特征有关，外存设备大体上可分为两类
		// 一类是顺序存取设备，例如磁带（tape）；另一类是直接存取设备，例如磁盘（disk）
		// 对于磁盘来说，一般有读写头、主轴、盘面、柱面、磁带等物理和逻辑结构组成
		// 一般情况下，把一次向磁盘写入或读出的数据称为一个物理块，一个物理块通常由若干记录组成

		// 外排序的基本方法是归并排序法，它分为以下两个步骤
		// (1)、生成若干初始归并段（顺串，runs）：将一个文件（含待排序数据）中的数据分段读入内存，在内存中对其进行内排序，并将经过排序的数据段（有序段）写到多个外存文件上
		// (2)、多路归并：对这些初始归并段进行多遍归并，使得有序的归并段逐渐扩大，最后在外存上形成整个文件的单一归并段，也就完成了这个文件的外排序
		// 从中可以看出，外排序的时间主要花费在内、外存数据的交换（对应存取时间）和内排序上

		// 11.2 磁盘排序（disk sort）

		// 11.2.1 磁盘排序概述
		// 由于是直接存取设备，读写一个数据块的时间与当前读写头所处的位置关系不大，所以可以通过读写数据块的次数来衡量存取时间
		// 对磁盘中的文件 Fin 进行排序，通过算法将 Fin 文件中的记录一部分一部分地调入内存处理，产生若干个文件 F1，...，Fn，它们都是有序的，称为顺串（runs）
		// 然后再次将 F1，...，Fn 文件中的记录调入内存，通过相关的归并算法（几路归并则同时从几个文件的开头处理）产生一个有序文件 Fout，从而达到数据排序的目的
		// 不同于内排序，磁盘排序中元素移动的次数相对于记录读写次数和关键字比较次数可以忽略，所以一般不考虑元素移动的时间开销
		// 因此可以大致认为，磁盘排序时间 = 读写记录次数 + 关键字比较次数

		// 12.2.2 生成初始归并段
		// 一般情况下，初始归并段的个数越多，多路归并的性能越差，这里介绍一种 置换-选择排序（replacement selection sorting）算法，从而减少初始归并段的个数，如下：
		// (1)、从待排序文件中 Fin 中按内存工作区 WA 的容量（设为 w）读入 w 个记录，设归并段编号 i = 1
		// (2)、从 WA 中选出关键字最小的记录 Rmin
		// (3)、将 Rmin 记录输出到文件 Fi 中，作为当前归并段的一个记录
		// (4)、若 Fin 不为空，则从 Fin 中读入下一个记录到 WA 中替代刚输出的记录
		// (5)、在 WA 工作区中所有大于等于 Rmin 的记录中选择最小的记录作为新的 Rmin，转(3)，直到选不出这样的 Rmin
		// (6)、置 i = i + 1，开始一个新的归并段
		// (7)、若 WA 工作区不为空，转(2)，否则 WA 工作区为空，初始归并段已全部产生，算法结束
		// 显然，置换-选择排序算法生成的初始归并段的长度既与内存工作区WA的大小有关，也与输入文件中记录的排序次序有关
		// 可以证明，如果输入文件中的记录按关键字随机排列，所得到的初始归并段的平均长度为内存工作区大小的两倍
		// 在置换-选择排序算法中，内存工作区WA内频繁的操作是，从w个记录中选择一个关键字最小的记录，如果采用基于简单选择的排序方法，每次操作需要w-1次比较
		// 若输入文件有n个记录，则算法的时间复杂度为O(nw)，实际上这种频繁的操作可以采用败者树来实现，从w个记录中选择一个关键字最小的记录的时间为O(log2w)
		// 从而使置换-选择排序算法的时间复杂度降低为 O(n*log2w)

		// 12.2.3 多路平衡归并
		// 1、k 路平衡归并的效率分析
		// 所谓二路平衡归并（2-way balanced merge）就是每一趟从 m 个归并段得到 ⌈m/2⌉ 个归并段
		// 这样归并树就有 ⌈log2m⌉ + 1 层（根上归并完的那个结点单独占一层），需要对初始数据进行 ⌈log2m⌉ 遍扫描
		// 做类似的推广，当采用 k 路平衡归并时，相应的归并树有 ⌈logk(m)⌉ + 1 层，要对数据进行 s = ⌈logk(m)⌉ 遍扫描，显然 k 越大，磁盘的读写次数越少
		// 在进行 k 路归并时，在 k 个记录中选择最小者，如果采用基于简单比较的的排序方法，需要进行 k-1 次比较，每趟归并 u 个记录需要做 (u-1)*(k-1) 次关键字比较
		// 则 s 趟归并总共需要的关键字比较次数为 s*(u-1)*(k-1) = ⌈logk(m)⌉*(u-1)*(k-1) = ⌈log2m⌉*(u-1)*(k-1)/⌈log2k⌉
		// 从中可以看出，在初始归并段个数 m 与记录个数 u 确定时，其中的前两项是常量，而 (k-1)/⌈log2k⌉ 随着 k 的增大而增大
		// 因此，若 m 与 u 确定，在选择几路归并方案时，尽管增大归并路数 k 会减少磁盘读写次数，但 k 增大会增加关键字比较次数
		// 当 k 增大到一定程度，就会抵消由于减少磁盘读写次数所赢得的时间
		// 也就是说，在 k 路平衡归并中，如果采用基于简单选择排序方法，其效率并非 k 越大，归并的效率就越好
		// 2、利用败者树的 k 路平衡归并


	} // END namespace _11 外排序

} // END namespace dst

#endif DST_11_12_13